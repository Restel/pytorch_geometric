{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import custom_graphgym  # noqa, register custom modules\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch_geometric.graphgym.cmd_args import parse_args\n",
    "from torch_geometric.graphgym.config import (\n",
    "    cfg,\n",
    "    dump_cfg,\n",
    "    load_cfg,\n",
    "    set_out_dir,\n",
    "    set_run_dir,\n",
    ")\n",
    "from torch_geometric.graphgym.logger import set_printing\n",
    "from torch_geometric.graphgym.model_builder import create_model\n",
    "from torch_geometric.graphgym.train import GraphGymDataModule, train\n",
    "from torch_geometric.graphgym.utils.agg_runs import agg_runs\n",
    "from torch_geometric.graphgym.utils.comp_budget import params_count\n",
    "from torch_geometric.graphgym.utils.device import auto_select_device\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.graphgym import register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook covers dataset creation, config load and training procedures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the input arguments for the script\n",
    "\n",
    "import argparse\n",
    "\n",
    "class NotebookArgParser:\n",
    "    def __init__(self, args_str):\n",
    "        self.args = self.parse_args(args_str)\n",
    "\n",
    "    def parse_args(self, args_str):\n",
    "        parser = argparse.ArgumentParser(description='GraphGym')\n",
    "\n",
    "        # Add command-line arguments\n",
    "        parser.add_argument('--cfg',\n",
    "                            dest='cfg_file',\n",
    "                            type=str,\n",
    "                            required=True,\n",
    "                            help='The configuration file path.')\n",
    "        parser.add_argument('--repeat',\n",
    "                            type=int,\n",
    "                            default=1,\n",
    "                            help='The number of repeated jobs.')\n",
    "        parser.add_argument('--mark_done',\n",
    "                            action='store_true',\n",
    "                            help='Mark yaml as done after a job has finished.')\n",
    "        parser.add_argument('opts',\n",
    "                            default=None,\n",
    "                            nargs=argparse.REMAINDER,\n",
    "                            help='See graphgym/config.py for remaining options.')\n",
    "\n",
    "        # Parse the command-line arguments\n",
    "        args = parser.parse_args(args_str)\n",
    "\n",
    "        return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = 'yeast_static'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Arguments:\n",
      "Configuration File: ./configs/pyg/yeast_static.yaml\n",
      "Repeat: 1\n",
      "Mark Done: False\n",
      "Remaining Options: []\n"
     ]
    }
   ],
   "source": [
    "# Emulate command-line arguments using input cells\n",
    "command = f\"python main_pyg.py --cfg ./configs/pyg/{config_name}.yaml --repeat 1\"\n",
    "args_str = command.split()[2:]\n",
    "# Create a NotebookArgParser instance\n",
    "notebook_parser = NotebookArgParser(args_str)\n",
    "\n",
    "# Access parsed arguments\n",
    "args = notebook_parser.args\n",
    "print(\"Parsed Arguments:\")\n",
    "print(f\"Configuration File: {args.cfg_file}\")\n",
    "print(f\"Repeat: {args.repeat}\")\n",
    "print(f\"Mark Done: {args.mark_done}\")\n",
    "print(f\"Remaining Options: {args.opts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_parser = NotebookArgParser(args_str)\n",
    "\n",
    "# Access parsed arguments\n",
    "args = notebook_parser.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_configs = './configs/pyg'\n",
    "\n",
    "configs = ['yeast_temporal', 'yeast_static', 'ecoli_temporal', 'ecoli_static']\n",
    "data_type = ['yeast', 'yeast', 'ecoli', 'ecoli']\n",
    "stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporal\n",
      "yeast-ppi\n",
      "DOWNLOADING CUSTOM DATASET LOADER\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.197/BIOGRID-ALL-4.4.197.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.198/BIOGRID-ALL-4.4.198.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.199/BIOGRID-ALL-4.4.199.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.200/BIOGRID-ALL-4.4.200.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.201/BIOGRID-ALL-4.4.201.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.202/BIOGRID-ALL-4.4.202.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.203/BIOGRID-ALL-4.4.203.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.204/BIOGRID-ALL-4.4.204.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.205/BIOGRID-ALL-4.4.205.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.206/BIOGRID-ALL-4.4.206.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.207/BIOGRID-ALL-4.4.207.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.208/BIOGRID-ALL-4.4.208.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.209/BIOGRID-ALL-4.4.209.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.210/BIOGRID-ALL-4.4.210.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.211/BIOGRID-ALL-4.4.211.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.212/BIOGRID-ALL-4.4.212.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.213/BIOGRID-ALL-4.4.213.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.214/BIOGRID-ALL-4.4.214.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.215/BIOGRID-ALL-4.4.215.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.216/BIOGRID-ALL-4.4.216.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.217/BIOGRID-ALL-4.4.217.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.218/BIOGRID-ALL-4.4.218.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.219/BIOGRID-ALL-4.4.219.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.220/BIOGRID-ALL-4.4.220.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.221/BIOGRID-ALL-4.4.221.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.222/BIOGRID-ALL-4.4.222.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.223/BIOGRID-ALL-4.4.223.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.224/BIOGRID-ALL-4.4.224.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.225/BIOGRID-ALL-4.4.225.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.226/BIOGRID-ALL-4.4.226.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.227/BIOGRID-ALL-4.4.227.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.228/BIOGRID-ALL-4.4.228.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.229/BIOGRID-ALL-4.4.229.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.230/BIOGRID-ALL-4.4.230.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.231/BIOGRID-ALL-4.4.231.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.232/BIOGRID-ALL-4.4.232.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.233/BIOGRID-ALL-4.4.233.tab3.zip\n",
      "File already exists\n",
      "datasets/yeast-ppi/yeast-ppi/processed/data.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/io/bionetworks.py:55: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep='\\t', header=0, usecols=columns_needed)\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/data/in_memory_dataset.py:301: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of splits is defined by the user\n",
      "[0, 12, 29, 33, 36]\n",
      "Positive edges 17244\n",
      "Positive edges 7129\n",
      "Negative edges 7129\n",
      "Positive edges 14316\n",
      "Negative edges 14316\n",
      "Positive edges 2428\n",
      "Negative edges 2428\n",
      "resetting share dim in for GNN model to: 5955\n",
      "static\n",
      "yeast-ppi\n",
      "DOWNLOADING CUSTOM DATASET LOADER\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.197/BIOGRID-ALL-4.4.197.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.198/BIOGRID-ALL-4.4.198.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.199/BIOGRID-ALL-4.4.199.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.200/BIOGRID-ALL-4.4.200.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.201/BIOGRID-ALL-4.4.201.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.202/BIOGRID-ALL-4.4.202.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.203/BIOGRID-ALL-4.4.203.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.204/BIOGRID-ALL-4.4.204.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.205/BIOGRID-ALL-4.4.205.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.206/BIOGRID-ALL-4.4.206.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.207/BIOGRID-ALL-4.4.207.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.208/BIOGRID-ALL-4.4.208.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.209/BIOGRID-ALL-4.4.209.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.210/BIOGRID-ALL-4.4.210.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.211/BIOGRID-ALL-4.4.211.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.212/BIOGRID-ALL-4.4.212.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.213/BIOGRID-ALL-4.4.213.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.214/BIOGRID-ALL-4.4.214.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.215/BIOGRID-ALL-4.4.215.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.216/BIOGRID-ALL-4.4.216.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.217/BIOGRID-ALL-4.4.217.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.218/BIOGRID-ALL-4.4.218.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.219/BIOGRID-ALL-4.4.219.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.220/BIOGRID-ALL-4.4.220.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.221/BIOGRID-ALL-4.4.221.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.222/BIOGRID-ALL-4.4.222.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.223/BIOGRID-ALL-4.4.223.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.224/BIOGRID-ALL-4.4.224.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.225/BIOGRID-ALL-4.4.225.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.226/BIOGRID-ALL-4.4.226.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.227/BIOGRID-ALL-4.4.227.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.228/BIOGRID-ALL-4.4.228.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.229/BIOGRID-ALL-4.4.229.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.230/BIOGRID-ALL-4.4.230.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.231/BIOGRID-ALL-4.4.231.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.232/BIOGRID-ALL-4.4.232.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.233/BIOGRID-ALL-4.4.233.tab3.zip\n",
      "File already exists\n",
      "The number of splits is defined by the user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting share dim in for GNN model to: 5955\n",
      "temporal\n",
      "Ecoli\n",
      "DOWNLOADING CUSTOM DATASET LOADER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/data/dataset.py:242: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you want to make use of another pre-processing technique, pass `force_reload=True` explicitly to reload the dataset.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of splits is defined by the user\n",
      "Positive edges 373\n",
      "Positive edges 307\n",
      "Negative edges 307\n",
      "Positive edges 180\n",
      "Negative edges 180\n",
      "Positive edges 172\n",
      "Negative edges 172\n",
      "resetting share dim in for GNN model to: 2608\n",
      "static\n",
      "Ecoli\n",
      "DOWNLOADING CUSTOM DATASET LOADER\n",
      "The number of splits is defined by the user\n",
      "resetting share dim in for GNN model to: 2608\n"
     ]
    }
   ],
   "source": [
    "for dataset,type in zip(configs, data_type):\n",
    "    config_path = f'{path_to_configs}/{dataset}.yaml'\n",
    "    cfg.merge_from_file(config_path)\n",
    "    print(cfg.dataset.split_type)\n",
    "    print(cfg.dataset.name)\n",
    "    if type == 'yeast':\n",
    "        datamodule = register.train_dict[\"BioGridGraphGymDataModule\"](split_type = cfg.dataset.split_type)\n",
    "    else:\n",
    "        datamodule = register.train_dict[\"CustomGraphGymDataModule\"](split_type = cfg.dataset.split_type)\n",
    "    statistics = datamodule._get_split_statistics()\n",
    "    stats.append(statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[            # MPP edges  # label pos edges  # label neg edges\n",
       "  train            102863              17244                  0\n",
       "  val              120107               7129               7129\n",
       "  test             127236              14316              14316\n",
       "  final_test       127236               2428               2428],\n",
       " [            # MPP edges  # label pos edges  # label neg edges\n",
       "  train            105910              18690                  0\n",
       "  val              124600              15574              15574\n",
       "  test             140174              15574              15574\n",
       "  final_test       140174               2428               2428],\n",
       " [            # MPP edges  # label pos edges  # label neg edges\n",
       "  train              6647                373                  0\n",
       "  val                6788                307                307\n",
       "  test               7065                180                180\n",
       "  final_test         7065                172                172],\n",
       " [            # MPP edges  # label pos edges  # label neg edges\n",
       "  train              5653               5653                  0\n",
       "  val                5653                706                706\n",
       "  test               6359                706                706\n",
       "  final_test         6359                347                347]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>num_self_loops</th>\n",
       "      <th>num_connected_components</th>\n",
       "      <th>avg_degree</th>\n",
       "      <th>validated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>2608</td>\n",
       "      <td>1498</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>0.574387</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005</td>\n",
       "      <td>2608</td>\n",
       "      <td>3300</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1.265337</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>2608</td>\n",
       "      <td>4589</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>1.759586</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>2608</td>\n",
       "      <td>6034</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>2.313650</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>2608</td>\n",
       "      <td>6502</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>2.493098</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014</td>\n",
       "      <td>2608</td>\n",
       "      <td>6647</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>2.548696</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015</td>\n",
       "      <td>2608</td>\n",
       "      <td>6559</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>2.514954</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>2608</td>\n",
       "      <td>6788</td>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "      <td>2.602761</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>2608</td>\n",
       "      <td>7065</td>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "      <td>2.708972</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020</td>\n",
       "      <td>2608</td>\n",
       "      <td>7187</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>2.755752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022</td>\n",
       "      <td>2608</td>\n",
       "      <td>7322</td>\n",
       "      <td>129</td>\n",
       "      <td>5</td>\n",
       "      <td>2.807515</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  num_nodes  num_edges  num_self_loops  num_connected_components  \\\n",
       "0   2003       2608       1498              49                        20   \n",
       "1   2005       2608       3300              65                         2   \n",
       "2   2006       2608       4589              87                         2   \n",
       "3   2011       2608       6034             111                         4   \n",
       "4   2013       2608       6502             117                         3   \n",
       "5   2014       2608       6647             119                         4   \n",
       "6   2015       2608       6559             120                         5   \n",
       "7   2017       2608       6788             125                         5   \n",
       "8   2018       2608       7065             125                         5   \n",
       "9   2020       2608       7187             128                         5   \n",
       "10  2022       2608       7322             129                         5   \n",
       "\n",
       "    avg_degree  validated  \n",
       "0     0.574387       True  \n",
       "1     1.265337       True  \n",
       "2     1.759586       True  \n",
       "3     2.313650       True  \n",
       "4     2.493098       True  \n",
       "5     2.548696       True  \n",
       "6     2.514954       True  \n",
       "7     2.602761       True  \n",
       "8     2.708972       True  \n",
       "9     2.755752       True  \n",
       "10    2.807515       True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.dataset.compute_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model with a chosen config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2025\n",
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/data/in_memory_dataset.py:301: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BIOGRID\n",
      "DOWNLOADING CUSTOM DATASET LOADER\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.197/BIOGRID-ALL-4.4.197.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.198/BIOGRID-ALL-4.4.198.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.199/BIOGRID-ALL-4.4.199.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.200/BIOGRID-ALL-4.4.200.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.201/BIOGRID-ALL-4.4.201.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.202/BIOGRID-ALL-4.4.202.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.203/BIOGRID-ALL-4.4.203.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.204/BIOGRID-ALL-4.4.204.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.205/BIOGRID-ALL-4.4.205.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.206/BIOGRID-ALL-4.4.206.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.207/BIOGRID-ALL-4.4.207.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.208/BIOGRID-ALL-4.4.208.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.209/BIOGRID-ALL-4.4.209.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.210/BIOGRID-ALL-4.4.210.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.211/BIOGRID-ALL-4.4.211.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.212/BIOGRID-ALL-4.4.212.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.213/BIOGRID-ALL-4.4.213.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.214/BIOGRID-ALL-4.4.214.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.215/BIOGRID-ALL-4.4.215.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.216/BIOGRID-ALL-4.4.216.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.217/BIOGRID-ALL-4.4.217.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.218/BIOGRID-ALL-4.4.218.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.219/BIOGRID-ALL-4.4.219.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.220/BIOGRID-ALL-4.4.220.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.221/BIOGRID-ALL-4.4.221.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.222/BIOGRID-ALL-4.4.222.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.223/BIOGRID-ALL-4.4.223.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.224/BIOGRID-ALL-4.4.224.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.225/BIOGRID-ALL-4.4.225.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.226/BIOGRID-ALL-4.4.226.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.227/BIOGRID-ALL-4.4.227.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.228/BIOGRID-ALL-4.4.228.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.229/BIOGRID-ALL-4.4.229.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.230/BIOGRID-ALL-4.4.230.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.231/BIOGRID-ALL-4.4.231.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.232/BIOGRID-ALL-4.4.232.tab3.zip\n",
      "File already exists\n",
      "Trying to access: https://downloads.thebiogrid.org/Download/BioGRID/Release-Archive/BIOGRID-4.4.233/BIOGRID-ALL-4.4.233.tab3.zip\n",
      "File already exists\n",
      "The number of splits is defined by the user\n",
      "resetting share dim in for GNN model to: 5955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu13/s18/lb9849/BioCompute/pytorch_geometric/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZING NEW CUSTOM EDGE HEAD\n",
      "GraphGymModule(\n",
      "  (model): GNN(\n",
      "    (encoder): FeatureEncoder()\n",
      "    (pre_mp): GeneralMultiLayer(\n",
      "      (Layer_0): GeneralLayer(\n",
      "        (layer): Linear(\n",
      "          (model): Linear(5955, 32, bias=True)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mp): GNNStackStage(\n",
      "      (layer0): GeneralLayer(\n",
      "        (layer): GATConv(\n",
      "          (model): GATConv(32, 32, heads=1)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (layer1): GeneralLayer(\n",
      "        (layer): GATConv(\n",
      "          (model): GATConv(64, 32, heads=1)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (post_mp): ExampleGNNEdgeHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): Linear(\n",
      "            (model): Linear(32, 32, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  downsample_test: True\n",
      "  downsample_test_rate: 0.5\n",
      "  edge_dim: 128\n",
      "  edge_encoder: False\n",
      "  edge_encoder_bn: True\n",
      "  edge_encoder_name: Bond\n",
      "  edge_message_ratio: 0.85\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: disjoint\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: yeast-ppi\n",
      "  node_encoder: False\n",
      "  node_encoder_bn: True\n",
      "  node_encoder_name: Atom\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: True\n",
      "  shuffle_split: True\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_mode: random\n",
      "  split_type: static\n",
      "  task: link_pred\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: True\n",
      "  transform: []\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: add\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 32\n",
      "  dropout: 0.0\n",
      "  head: custom\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: gatconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 1\n",
      "  layers_pre_mp: 1\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: skipconcat\n",
      "gpu_mem: False\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: auto\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: add\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: gnn\n",
      "num_threads: 6\n",
      "num_workers: 10\n",
      "optim:\n",
      "  base_lr: 0.01\n",
      "  early_stop: False\n",
      "  early_stop_criterion: val_aupr\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 200\n",
      "  momentum: 0.9\n",
      "  optimizer: adam\n",
      "  patience: 5\n",
      "  scheduler: None\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 0.0005\n",
      "out_dir: results/yeast/yeast_static\n",
      "print: both\n",
      "round: 4\n",
      "run_dir: results/yeast/yeast_static/0\n",
      "seed: 2025\n",
      "share:\n",
      "  dim_in: 5955\n",
      "  dim_out: 1\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 32\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "trainer_testing: True\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "Num parameters: 194912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: results/yeast/yeast_static/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | GNN  | 194 K \n",
      "-------------------------------\n",
      "194 K     Trainable params\n",
      "0         Non-trainable params\n",
      "194 K     Total params\n",
      "0.780     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|| 1/1 [00:00<00:00,  2.90it/s]val: {'epoch': 0, 'loss': 0.8252, 'lr': 0.01, 'params': 194912, 'time_iter': 0.5508, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6667, 'auc': 0.5625, 'aupr': 0.4982, 'mrr': 0.0002, 'hit_K': 12.0}\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu13/s18/lb9849/miniconda3/envs/pyg/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] Samping new training neg edges: torch.Size([2, 18690])\n",
      "Epoch 0: 100%|| 1/1 [00:00<00:00,  2.70it/s, v_num=0]val: {'epoch': 0, 'loss': 0.7038, 'lr': 0.01, 'params': 194912, 'time_iter': 0.2293, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6667, 'auc': 0.6938, 'aupr': 0.649, 'mrr': 0.0003, 'hit_K': 20.0}\n",
      "Epoch 0: 100%|| 1/1 [00:00<00:00,  1.13it/s, v_num=0, val_accuracy=0.500, val_precision=0.500, val_recall=1.000, val_f1=0.667, val_auc=0.694, val_aupr=0.649, val_mrr=0.0003, val_hit_K=20.00]train: {'epoch': 0, 'eta': 73.4572, 'loss': 0.8234, 'lr': 0.01, 'params': 194912, 'time_iter': 0.3691, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6667, 'auc': 0.5838, 'aupr': 0.5111, 'mrr': 0.0002, 'hit_K': 16.0}\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, val_accuracy=0.500, val_precision=0.500, val_recall=1.000, val_f1=0.667, val_auc=0.694, val_aupr=0.649, val_mrr=0.0003, val_hit_K=20.00]        Samping new training neg edges: torch.Size([2, 18690])\n",
      "Epoch 1: 100%|| 1/1 [00:00<00:00,  3.68it/s, v_num=0, val_accuracy=0.500, val_precision=0.500, val_recall=1.000, val_f1=0.667, val_auc=0.694, val_aupr=0.649, val_mrr=0.0003, val_hit_K=20.00]val: {'epoch': 1, 'loss': 0.6952, 'lr': 0.01, 'params': 194912, 'time_iter': 0.2265, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6667, 'auc': 0.7636, 'aupr': 0.7496, 'mrr': 0.0003, 'hit_K': 52.0}\n",
      "Epoch 1: 100%|| 1/1 [00:00<00:00,  1.40it/s, v_num=0, val_accuracy=0.500, val_precision=0.500, val_recall=1.000, val_f1=0.667, val_auc=0.764, val_aupr=0.750, val_mrr=0.0003, val_hit_K=52.00]train: {'epoch': 1, 'eta': 63.3428, 'loss': 0.7037, 'lr': 0.01, 'params': 194912, 'time_iter': 0.2707, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6667, 'auc': 0.6938, 'aupr': 0.6475, 'mrr': 0.0002, 'hit_K': 13.0}\n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, val_accuracy=0.500, val_precision=0.500, val_recall=1.000, val_f1=0.667, val_auc=0.764, val_aupr=0.750, val_mrr=0.0003, val_hit_K=52.00]        Samping new training neg edges: torch.Size([2, 18690])\n",
      "Epoch 2: 100%|| 1/1 [00:00<00:00,  3.86it/s, v_num=0, val_accuracy=0.500, val_precision=0.500, val_recall=1.000, val_f1=0.667, val_auc=0.764, val_aupr=0.750, val_mrr=0.0003, val_hit_K=52.00]val: {'epoch': 2, 'loss': 0.6904, 'lr': 0.01, 'params': 194912, 'time_iter': 0.2215, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6667, 'auc': 0.8344, 'aupr': 0.8358, 'mrr': 0.0006, 'hit_K': 98.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu13/s18/lb9849/miniconda3/envs/pyg/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 1: 100%|| 1/1 [00:00<00:00, 15.58it/s]test_split_0: {'epoch': 2, 'loss': 0.6906, 'lr': 0.01, 'params': 194912, 'time_iter': 0.2704, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6667, 'auc': 0.8273, 'aupr': 0.8312, 'mrr': 0.0006, 'hit_K': 97.0}\n",
      "test_split_1: {'epoch': 2, 'loss': 0.6916, 'lr': 0.01, 'params': 194912, 'time_iter': 0.7494, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6667, 'auc': 0.8107, 'aupr': 0.7763, 'mrr': 0.0028, 'hit_K': 93.0}\n",
      "Testing DataLoader 1: 100%|| 1/1 [00:00<00:00,  4.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load config file\n",
    "load_cfg(cfg, args)\n",
    "set_out_dir(cfg.out_dir, args.cfg_file)\n",
    "# Set Pytorch environment\n",
    "torch.set_num_threads(cfg.num_threads)\n",
    "dump_cfg(cfg)\n",
    "# Repeat for different random seeds\n",
    "for i in range(args.repeat):\n",
    "    set_run_dir(cfg.out_dir, i)\n",
    "    set_printing()\n",
    "    # Set configurations for each run\n",
    "    cfg.seed = cfg.seed + 1\n",
    "    seed_everything(cfg.seed, workers=True)\n",
    "    auto_select_device() # if not set in the yaml config, set to cuda accelerator if available and single device\n",
    "    # Set machine learning pipeline\n",
    "    if cfg.dataset.name in ['yeast-ppi']:\n",
    "            print('Loading BIOGRID')\n",
    "            datamodule = register.train_dict[\"BioGridGraphGymDataModule\"](split_type = cfg.dataset.split_type)    \n",
    "    else:\n",
    "        print('Loading grn-ecoli')\n",
    "        datamodule = register.train_dict[\"CustomGraphGymDataModule\"](split_type = cfg.dataset.split_type)\n",
    "    cfg.share.dim_out = 1 \n",
    "    cfg.share.num_splits = 3\n",
    "    model = create_model()\n",
    "    # Print model info\n",
    "    logging.info(model)\n",
    "    logging.info(cfg)\n",
    "    cfg.params = params_count(model)\n",
    "    logging.info('Num parameters: %s', cfg.params)\n",
    "    # Call the custom training function\n",
    "    register.train_dict[\"train_pl\"](model, datamodule, logger=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

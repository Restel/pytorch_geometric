{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import custom_graphgym  # noqa, register custom modules\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch_geometric.graphgym.cmd_args import parse_args\n",
    "from torch_geometric.graphgym.config import (\n",
    "    cfg,\n",
    "    dump_cfg,\n",
    "    load_cfg,\n",
    "    set_out_dir,\n",
    "    set_run_dir,\n",
    ")\n",
    "from torch_geometric.graphgym.logger import set_printing\n",
    "from torch_geometric.graphgym.model_builder import create_model\n",
    "from torch_geometric.graphgym.train import GraphGymDataModule, train\n",
    "from torch_geometric.graphgym.utils.agg_runs import agg_runs\n",
    "from torch_geometric.graphgym.utils.comp_budget import params_count\n",
    "from torch_geometric.graphgym.utils.device import auto_select_device\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.graphgym import register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook covers dataset creation, config load and training procedures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the input arguments for the script\n",
    "\n",
    "import argparse\n",
    "\n",
    "class NotebookArgParser:\n",
    "    def __init__(self, args_str):\n",
    "        self.args = self.parse_args(args_str)\n",
    "\n",
    "    def parse_args(self, args_str):\n",
    "        parser = argparse.ArgumentParser(description='GraphGym')\n",
    "\n",
    "        # Add command-line arguments\n",
    "        parser.add_argument('--cfg',\n",
    "                            dest='cfg_file',\n",
    "                            type=str,\n",
    "                            required=True,\n",
    "                            help='The configuration file path.')\n",
    "        parser.add_argument('--repeat',\n",
    "                            type=int,\n",
    "                            default=1,\n",
    "                            help='The number of repeated jobs.')\n",
    "        parser.add_argument('--mark_done',\n",
    "                            action='store_true',\n",
    "                            help='Mark yaml as done after a job has finished.')\n",
    "        parser.add_argument('opts',\n",
    "                            default=None,\n",
    "                            nargs=argparse.REMAINDER,\n",
    "                            help='See graphgym/config.py for remaining options.')\n",
    "\n",
    "        # Parse the command-line arguments\n",
    "        args = parser.parse_args(args_str)\n",
    "\n",
    "        return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = 'yeast_static'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Arguments:\n",
      "Configuration File: ./configs/pyg/yeast_static.yaml\n",
      "Repeat: 1\n",
      "Mark Done: False\n",
      "Remaining Options: []\n"
     ]
    }
   ],
   "source": [
    "# Emulate command-line arguments using input cells\n",
    "command = f\"python main_pyg.py --cfg ./configs/pyg/{config_name}.yaml --repeat 1\"\n",
    "args_str = command.split()[2:]\n",
    "# Create a NotebookArgParser instance\n",
    "notebook_parser = NotebookArgParser(args_str)\n",
    "\n",
    "# Access parsed arguments\n",
    "args = notebook_parser.args\n",
    "print(\"Parsed Arguments:\")\n",
    "print(f\"Configuration File: {args.cfg_file}\")\n",
    "print(f\"Repeat: {args.repeat}\")\n",
    "print(f\"Mark Done: {args.mark_done}\")\n",
    "print(f\"Remaining Options: {args.opts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_parser = NotebookArgParser(args_str)\n",
    "\n",
    "# Access parsed arguments\n",
    "args = notebook_parser.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "load_cfg(cfg, args)\n",
    "set_out_dir(cfg.out_dir, args.cfg_file)\n",
    "# Set Pytorch environment\n",
    "torch.set_num_threads(cfg.num_threads)\n",
    "dump_cfg(cfg)\n",
    "# Repeat for different random seeds\n",
    "for i in range(args.repeat):\n",
    "    set_run_dir(cfg.out_dir, i)\n",
    "    set_printing()\n",
    "    # Set configurations for each run\n",
    "    cfg.seed = cfg.seed + 1\n",
    "    seed_everything(cfg.seed, workers=True)\n",
    "    auto_select_device() # if not set in the yaml config, set to cuda accelerator if available and single device\n",
    "    # Set machine learning pipeline\n",
    "    if cfg.dataset.name in ['yeast-ppi']:\n",
    "            print('Loading BIOGRID')\n",
    "            datamodule = register.train_dict[\"BioGridGraphGymDataModule\"](split_type = cfg.dataset.split_type)    \n",
    "    else:\n",
    "        print('Loading grn-ecoli')\n",
    "        datamodule = register.train_dict[\"CustomGraphGymDataModule\"](split_type = cfg.dataset.split_type)\n",
    "    cfg.share.dim_out = 1 \n",
    "    cfg.share.num_splits = 3\n",
    "    model = create_model()\n",
    "    # Print model info\n",
    "    logging.info(model)\n",
    "    logging.info(cfg)\n",
    "    cfg.params = params_count(model)\n",
    "    logging.info('Num parameters: %s', cfg.params)\n",
    "    # Call the custom training function\n",
    "    register.train_dict[\"train_pl\"](model, datamodule, logger=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
